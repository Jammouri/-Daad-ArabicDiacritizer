{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -This is our unsuccessful trial to use Transformer architecture to create the model \n",
    "#### We think that could be useful to keep it for future reference\n",
    "\n",
    "### -Our thoughts:\n",
    "##### 1. We think that the model could be too complex for this task\n",
    "##### 2. Or there are some mistakes in the implementation especially in initializing the weights of the model and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout, kernel_size=3):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.conv1d = nn.Conv1d(in_channels=d_model, out_channels=d_model, kernel_size=kernel_size, padding=1)  # Add 1d conv\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        x = self.conv1d(x.permute(0, 2, 1))  # Permute for 1d conv (batch, features, seq_len)\n",
    "        x = x.permute(0, 2, 1)  # Permute back\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout, kernel_size=3):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.conv1d = nn.Conv1d(in_channels=d_model, out_channels=d_model, kernel_size=kernel_size, padding=1)  # Add 1d conv\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        x = self.conv1d(x.permute(0, 2, 1))  # Permute for 1d conv\n",
    "        x = x.permute(0, 2, 1)  # Permute back\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        nopeak_mask = nopeak_mask.to(tgt.device)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "DATASET_PATH = 'Data'\n",
    "\n",
    "train_data_raw = []\n",
    "valid_data_raw = []\n",
    "test_data_raw = []\n",
    "\n",
    "for i in range(1, 30):\n",
    "    filename = f\"/tashkeela_train/tashkeela_train_{i:03}.txt\"\n",
    "    with open(DATASET_PATH + filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        train_data_raw.extend(lines)\n",
    "\n",
    "\n",
    "for i in range(1, 5):\n",
    "    filename = f\"/tashkeela_val/tashkeela_val_{i:03}.txt\"\n",
    "    with open(DATASET_PATH + filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        valid_data_raw.extend(lines)\n",
    "\n",
    "for i in range(1, 2):\n",
    "    filename = f\"/tashkeela_test/tashkeela_test_{i:03}.txt\"\n",
    "    with open(DATASET_PATH + filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        test_data_raw.extend(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH_EXTRA_TRAIN = False\n",
    "DATASET_PATH = 'Data'\n",
    "CONSTANTS_PATH = 'helpers/constants'\n",
    "\n",
    "with open(CONSTANTS_PATH + '/ARABIC_LETTERS_LIST.pickle', 'rb') as file:\n",
    "    ARABIC_LETTERS_LIST = pkl.load(file)\n",
    "with open(CONSTANTS_PATH + '/DIACRITICS_LIST.pickle', 'rb') as file:\n",
    "    DIACRITICS_LIST = pkl.load(file)\n",
    "if not WITH_EXTRA_TRAIN:\n",
    "    with open(CONSTANTS_PATH + '/RNN_BIG_CHARACTERS_MAPPING.pickle', 'rb') as file:\n",
    "        CHARACTERS_MAPPING = pkl.load(file)\n",
    "else:\n",
    "    with open(CONSTANTS_PATH + '/RNN_BIG_CHARACTERS_MAPPING.pickle', 'rb') as file:\n",
    "        CHARACTERS_MAPPING = pkl.load(file)\n",
    "with open(CONSTANTS_PATH + '/RNN_CLASSES_MAPPING.pickle', 'rb') as file:\n",
    "    CLASSES_MAPPING = pkl.load(file)\n",
    "with open(CONSTANTS_PATH + '/RNN_REV_CLASSES_MAPPING.pickle', 'rb') as file:\n",
    "    REV_CLASSES_MAPPING = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(data_raw):\n",
    "    return data_raw.translate(str.maketrans('', '', ''.join(DIACRITICS_LIST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_raw):\n",
    "    data_new = list()\n",
    "\n",
    "    for line in data_raw:\n",
    "        for sub_line in line.split('\\n'):\n",
    "            if len(remove_diacritics(sub_line).strip()) == 0:\n",
    "                continue\n",
    "\n",
    "            if len(remove_diacritics(sub_line).strip()) > 0 and len(remove_diacritics(sub_line).strip()) <= 500:\n",
    "                data_new.append(sub_line.strip())\n",
    "            else:\n",
    "                sub_line = sub_line.split()\n",
    "                tmp_line = ''\n",
    "                for word in sub_line:\n",
    "                    if len(remove_diacritics(tmp_line).strip()) + len(remove_diacritics(word).strip()) + 1 > 500:\n",
    "                        if len(remove_diacritics(tmp_line).strip()) > 0:\n",
    "                            data_new.append(tmp_line.strip())\n",
    "                        tmp_line = word\n",
    "                    else:\n",
    "                        if tmp_line == '':\n",
    "                            tmp_line = word\n",
    "                        else:\n",
    "                            tmp_line += ' '\n",
    "                            tmp_line += word\n",
    "                if len(remove_diacritics(tmp_line).strip()) > 0:\n",
    "                    data_new.append(tmp_line.strip())\n",
    "\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = split_data(train_data_raw)\n",
    "val_split = split_data(valid_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training examples (split):', len(train_split))\n",
    "print('Validation examples (split):', len(val_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(data_raw):\n",
    "    X = list()\n",
    "    Y = list()\n",
    "\n",
    "    for line in data_raw:\n",
    "        x = [CHARACTERS_MAPPING['<SOS>']]\n",
    "        y = [CLASSES_MAPPING['<SOS>']]\n",
    "\n",
    "        for idx, char in enumerate(line):\n",
    "                if char in DIACRITICS_LIST:\n",
    "                    continue\n",
    "\n",
    "                # if char wasn't a diacritic add it to x\n",
    "                try:\n",
    "                    x.append(CHARACTERS_MAPPING[char])\n",
    "                except KeyError as e:\n",
    "                    print(f\"Error: Character '{char}' not found in CHARACTERS_MAPPING at index {idx} in line: {line}\")\n",
    "\n",
    "                # if char wasn't a diacritic and wasn't an arabic letter add '' to y (no diacritic)\n",
    "                if char not in ARABIC_LETTERS_LIST:\n",
    "                    y.append(CLASSES_MAPPING[''])\n",
    "                # if char was an arabic letter only.\n",
    "                else:\n",
    "                    char_diac = ''\n",
    "                    if idx + 1 < len(line) and line[idx + 1] in DIACRITICS_LIST:\n",
    "                        char_diac = line[idx + 1]\n",
    "                        if idx + 2 < len(line) and line[idx + 2] in DIACRITICS_LIST and char_diac + line[idx + 2] in CLASSES_MAPPING:\n",
    "                            char_diac += line[idx + 2]\n",
    "                        elif idx + 2 < len(line) and line[idx + 2] in DIACRITICS_LIST and line[idx + 2] + char_diac in CLASSES_MAPPING: # شدة فتحة = فتحة شدة\n",
    "                            char_diac = line[idx + 2] + char_diac\n",
    "                    y.append(CLASSES_MAPPING[char_diac])\n",
    "\n",
    "        \n",
    "        assert(len(x) == len(y))\n",
    "\n",
    "        x.append(CHARACTERS_MAPPING['<EOS>'])\n",
    "        y.append(CLASSES_MAPPING['<EOS>'])\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "        # print(len(x))\n",
    "        # print(\"yyyyyyyyyyyyyyyyyyyyyy\")\n",
    "        # print(len(y))\n",
    "\n",
    "    # X = np.asarray(X)\n",
    "    # Y = np.asarray(Y)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, lines, batch_size):\n",
    "        self.lines = lines\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.lines) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.batch_size\n",
    "        end_idx = min((idx + 1) * self.batch_size, len(self.lines))\n",
    "        lines = self.lines[start_idx:end_idx]\n",
    "        X_batch, Y_batch = map_data(lines)\n",
    "\n",
    "        X_max_seq_len = 100\n",
    "        y_max_seq_len = 100\n",
    "\n",
    "        X = []\n",
    "        for x in X_batch:\n",
    "            x = list(x)\n",
    "            x = x[:X_max_seq_len]\n",
    "            x.extend([CHARACTERS_MAPPING['<PAD>']] * (X_max_seq_len - len(x)))\n",
    "            X.append(np.asarray(x))\n",
    "\n",
    "        Y_tmp = []\n",
    "        for y in Y_batch:\n",
    "            y_new = list(y)\n",
    "            y_new = y_new[:y_max_seq_len]\n",
    "            y_new.extend([CHARACTERS_MAPPING['<PAD>']] * (y_max_seq_len - len(y)))\n",
    "            Y_tmp.append(np.asarray(y_new))\n",
    "        Y_batch = Y_tmp\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        Y_batch = np.asarray(Y_batch)\n",
    "\n",
    "        return torch.tensor(X), torch.tensor(Y_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(batch_size, train_split, val_split):\n",
    "\n",
    "    random.shuffle(train_split)\n",
    "    train_split = list(sorted(train_split, key=lambda line: len(remove_diacritics(line)))) \n",
    "    random.shuffle(val_split)\n",
    "    val_split = list(sorted(val_split, key=lambda line: len(remove_diacritics(line))))\n",
    "\n",
    "    training_generator = MyDataset(train_split, batch_size)\n",
    "    val_generator = MyDataset(val_split, batch_size)\n",
    "\n",
    "    return training_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Gen, Val_Gen = fit_model(64, train_split, val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(CHARACTERS_MAPPING)\n",
    "tgt_vocab_size = len(CLASSES_MAPPING)\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the gpu for training the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model using the Training Generator and Validation Generator\n",
    "\n",
    "for epoch in range(3):\n",
    "    transformer.train()\n",
    "    for i in range(Train_Gen.__len__()):\n",
    "        optimizer.zero_grad()\n",
    "        source = Train_Gen.__getitem__(i)[0].to(device)\n",
    "        target = Train_Gen.__getitem__(i)[1].to(device)\n",
    "        output = transformer(source, target[:, :-1])\n",
    "        print(output.shape)\n",
    "        print(target.shape)\n",
    "        loss = criterion(output.contiguous().view(-1, tgt_vocab_size), target[:, 1:].contiguous().view(-1).type(torch.LongTensor).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}, Batch: {i+1}, Loss: {loss.item()}\")\n",
    "\n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(Val_Gen.__len__()):\n",
    "            source = Val_Gen.__getitem__(i)[0].to(device)\n",
    "            target = Val_Gen.__getitem__(i)[1].to(device)\n",
    "            output = transformer(source, target[:, :-1])\n",
    "            loss = criterion(output.contiguous().view(-1, tgt_vocab_size), target[:, 1:].contiguous().view(-1).type(torch.LongTensor).to(device))\n",
    "            print(f\"Epoch: {epoch+1}, Validation Batch: {i+1}, Loss: {loss.item()}\")\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(transformer, source_vector):\n",
    "    transformer.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients during inference\n",
    "        # Assuming target vector is not needed during inference\n",
    "        # Initialize target with zeros with appropriate shape\n",
    "        target_vector = torch.zeros((1, source_vector.size(1)), dtype=torch.long).to(source_vector.device)\n",
    "        # or initialize target with <SOS> token\n",
    "        output = transformer(source_vector, target_vector)  \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "torch.save(transformer, 'transformer6.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"السلام عليكم يا قوم\"\n",
    "\n",
    "X, _ = map_data([line])\n",
    "predictions = inference(transformer, torch.tensor(X).to(device))\n",
    "predictions = predictions.squeeze()\n",
    "#convert to numpy\n",
    "predictions = predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions[1:]\n",
    "\n",
    "    \n",
    "output = ''\n",
    "for char, prediction in zip(remove_diacritics(line), predictions):\n",
    "    output += char\n",
    "\n",
    "    if char not in ARABIC_LETTERS_LIST:\n",
    "        continue\n",
    "\n",
    "    if '<' in REV_CLASSES_MAPPING[np.argmax(prediction)]:\n",
    "        continue\n",
    "\n",
    "    output += REV_CLASSES_MAPPING[np.argmax(prediction)]\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
